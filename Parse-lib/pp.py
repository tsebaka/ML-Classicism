# -*- coding: utf-8 -*-
"""Untitled105.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aVHU-CDWzco2ZYD7Kol_fO-8NvPSV3qZ
"""

import numpy as np
import nltk
import bs4 as bs
import re
import urllib.request
import warnings

from nltk.corpus import stopwords

class parse_and_prepare():
    def __init__(self, EOS=False):
        self.vocab_size = 0
        self.vocab = np.array([])
        self.text = np.array([])
        self.EOS = EOS

    def parse(self, sites):
        self.count = len(sites)
        for site in sites:
            scrapped_data_second = urllib.request.urlopen(site)
            article_second = scrapped_data_second.read()

            parsed_article_second = bs.BeautifulSoup(article_second,'lxml')
            paragraphs_second = parsed_article_second.find_all('p')
            article_text_second = ""
            for p in paragraphs_second:
                article_text_second += p.text

            processed_article_second = article_text_second.lower()
            if EOS:
                processed_article_second = re.sub('[^a-zA-Z.]', ' ', processed_article_second)
            else:
                processed_article_second = re.sub('[^a-zA-Z]', ' ', processed_article_second)
            processed_article_second = re.sub('\s+', ' ', processed_article_second)
            all_sentences_second = nltk.sent_tokenize(processed_article_second)
            all_words_second = [nltk.word_tokenize(sent) for sent in all_sentences_second]

            for i in range(1):
                all_words_second[i] = [w for w in all_words_second[i] if w not in stopwords.words('english')]

            for word in all_words_second[0]:
                self.text = np.append(self.text, word)
                flag = 0
                for i in range(self.vocab_size):
                    if self.vocab[i] == word:
                        flag = 1
                        break
                if flag == 0:
                    self.vocab = np.append(self.vocab, word)
                    self.vocab_size += 1
        
        return self.vocab, self.text, all_words_second