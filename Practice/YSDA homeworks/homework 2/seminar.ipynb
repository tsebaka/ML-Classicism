{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13WLvPsoXzdj"
      },
      "source": [
        "# Large scale text analysis with deep learning (3 points)\n",
        "\n",
        "Today we're gonna apply the newly learned tools for the task of predicting job salary.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3342/media/salary%20prediction%20engine%20v2.png\" width=400px>\n",
        "\n",
        "_Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the core assignment idea._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lk5FTPY1Xzd7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "886c5yLZXzeC"
      },
      "source": [
        "### About the challenge\n",
        "For starters, let's download and unpack the data from [here]. \n",
        "\n",
        "You can also get it from [yadisk url](https://yadi.sk/d/vVEOWPFY3NruT7) the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31m7EdZUXzeD",
        "outputId": "f945de7f-12db-49df-9fbc-31edf273a2b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-13 14:49:29--  https://ysda-seminars.s3.eu-central-1.amazonaws.com/Train_rev1.zip\n",
            "Resolving ysda-seminars.s3.eu-central-1.amazonaws.com (ysda-seminars.s3.eu-central-1.amazonaws.com)... 52.219.47.56\n",
            "Connecting to ysda-seminars.s3.eu-central-1.amazonaws.com (ysda-seminars.s3.eu-central-1.amazonaws.com)|52.219.47.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128356352 (122M) [application/zip]\n",
            "Saving to: ‘Train_rev1.zip’\n",
            "\n",
            "Train_rev1.zip      100%[===================>] 122.41M  31.0MB/s    in 4.5s    \n",
            "\n",
            "2023-02-13 14:49:34 (26.9 MB/s) - ‘Train_rev1.zip’ saved [128356352/128356352]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(244768, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!wget https://ysda-seminars.s3.eu-central-1.amazonaws.com/Train_rev1.zip\n",
        "data = pd.read_csv(\"./Train_rev1.zip\", compression='zip', index_col=None)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "faRBxtH7XzeE",
        "outputId": "6fc7f78e-6920-49be-e5c7-1c0902ae06cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Id                                              Title  \\\n",
              "0  12612628                        Engineering Systems Analyst   \n",
              "1  12612830                            Stress Engineer Glasgow   \n",
              "2  12612844                   Modelling and simulation analyst   \n",
              "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
              "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
              "\n",
              "                                     FullDescription  \\\n",
              "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
              "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
              "2  Mathematical Modeller / Simulation Analyst / O...   \n",
              "3  Engineering Systems Analyst / Mathematical Mod...   \n",
              "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
              "\n",
              "                         LocationRaw LocationNormalized ContractType  \\\n",
              "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
              "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
              "2  Hampshire, South East, South East          Hampshire          NaN   \n",
              "3     Surrey, South East, South East             Surrey          NaN   \n",
              "4     Surrey, South East, South East             Surrey          NaN   \n",
              "\n",
              "  ContractTime                       Company          Category  \\\n",
              "0    permanent  Gregory Martin International  Engineering Jobs   \n",
              "1    permanent  Gregory Martin International  Engineering Jobs   \n",
              "2    permanent  Gregory Martin International  Engineering Jobs   \n",
              "3    permanent  Gregory Martin International  Engineering Jobs   \n",
              "4    permanent  Gregory Martin International  Engineering Jobs   \n",
              "\n",
              "                                SalaryRaw  SalaryNormalized        SourceName  \n",
              "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
              "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
              "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
              "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
              "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab7b5575-e3ed-4b5b-b2bb-55e4356ffbfe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12612628</td>\n",
              "      <td>Engineering Systems Analyst</td>\n",
              "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
              "      <td>Dorking, Surrey, Surrey</td>\n",
              "      <td>Dorking</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 30000/annum 20-30K</td>\n",
              "      <td>25000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12612830</td>\n",
              "      <td>Stress Engineer Glasgow</td>\n",
              "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
              "      <td>Glasgow, Scotland, Scotland</td>\n",
              "      <td>Glasgow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>25000 - 35000/annum 25-35K</td>\n",
              "      <td>30000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12612844</td>\n",
              "      <td>Modelling and simulation analyst</td>\n",
              "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
              "      <td>Hampshire, South East, South East</td>\n",
              "      <td>Hampshire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 40000/annum 20-40K</td>\n",
              "      <td>30000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12613049</td>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
              "      <td>27500</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12613647</td>\n",
              "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
              "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
              "      <td>Surrey, South East, South East</td>\n",
              "      <td>Surrey</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Gregory Martin International</td>\n",
              "      <td>Engineering Jobs</td>\n",
              "      <td>20000 - 30000/annum 20-30K</td>\n",
              "      <td>25000</td>\n",
              "      <td>cv-library.co.uk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab7b5575-e3ed-4b5b-b2bb-55e4356ffbfe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab7b5575-e3ed-4b5b-b2bb-55e4356ffbfe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab7b5575-e3ed-4b5b-b2bb-55e4356ffbfe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8NZq6TWXzeF"
      },
      "source": [
        "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
        "\n",
        "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n",
        "\n",
        "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "9H02fE26XzeF",
        "outputId": "ca27c081-302a-404f-ef59-a0517c5b8924"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data['Log1pSalary'], bins=20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XguRiwJXzeH"
      },
      "source": [
        "Our task is to predict one number, __Log1pSalary__.\n",
        "\n",
        "To do so, our model can access a number of features:\n",
        "* Free text: __`Title`__ and  __`FullDescription`__\n",
        "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "wOg6YYE0XzeI",
        "outputId": "43000cc5-00cc-444e-ea51-feb8e4a8dce0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Id                                              Title  \\\n",
              "42183   68413004  New Store Opening  Management Opportunities  D...   \n",
              "159416  71170943                         Account Executive  Digital   \n",
              "134829  70255276                                      QA Technician   \n",
              "\n",
              "                                          FullDescription  \\\n",
              "42183   The Roles:Due to our continuing success and ex...   \n",
              "159416  Account Executive  Digital ****  Excellent Bon...   \n",
              "134829  Our client is a major pharmaceutical manufactu...   \n",
              "\n",
              "                            LocationRaw LocationNormalized ContractType  \\\n",
              "42183                        Darlington         Darlington    full_time   \n",
              "159416                               UK                 UK          NaN   \n",
              "134829  Billingham Cleveland North East                 UK          NaN   \n",
              "\n",
              "       ContractTime                      Company              Category  \\\n",
              "42183           NaN  Sports Direct International      Consultancy Jobs   \n",
              "159416          NaN         Moriati Media UK Ltd            Sales Jobs   \n",
              "134829     contract                  CY Partners  Scientific & QA Jobs   \n",
              "\n",
              "                                                SalaryRaw  SalaryNormalized  \\\n",
              "42183   16,000.00 - 30,000.00 per year Basic Salary 16...             23000   \n",
              "159416                           22,000 + Excellent Bonus             22000   \n",
              "134829                    From 25,000 to 25,000 per annum             25000   \n",
              "\n",
              "               SourceName  Log1pSalary  \n",
              "42183      Jobcentre Plus    10.043293  \n",
              "159416  salestarget.co.uk     9.998843  \n",
              "134829      totaljobs.com    10.126671  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-534b7a81-18d4-4b50-8e67-01361ebad6b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "      <th>Log1pSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42183</th>\n",
              "      <td>68413004</td>\n",
              "      <td>New Store Opening  Management Opportunities  D...</td>\n",
              "      <td>The Roles:Due to our continuing success and ex...</td>\n",
              "      <td>Darlington</td>\n",
              "      <td>Darlington</td>\n",
              "      <td>full_time</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sports Direct International</td>\n",
              "      <td>Consultancy Jobs</td>\n",
              "      <td>16,000.00 - 30,000.00 per year Basic Salary 16...</td>\n",
              "      <td>23000</td>\n",
              "      <td>Jobcentre Plus</td>\n",
              "      <td>10.043293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159416</th>\n",
              "      <td>71170943</td>\n",
              "      <td>Account Executive  Digital</td>\n",
              "      <td>Account Executive  Digital ****  Excellent Bon...</td>\n",
              "      <td>UK</td>\n",
              "      <td>UK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moriati Media UK Ltd</td>\n",
              "      <td>Sales Jobs</td>\n",
              "      <td>22,000 + Excellent Bonus</td>\n",
              "      <td>22000</td>\n",
              "      <td>salestarget.co.uk</td>\n",
              "      <td>9.998843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134829</th>\n",
              "      <td>70255276</td>\n",
              "      <td>QA Technician</td>\n",
              "      <td>Our client is a major pharmaceutical manufactu...</td>\n",
              "      <td>Billingham Cleveland North East</td>\n",
              "      <td>UK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>contract</td>\n",
              "      <td>CY Partners</td>\n",
              "      <td>Scientific &amp; QA Jobs</td>\n",
              "      <td>From 25,000 to 25,000 per annum</td>\n",
              "      <td>25000</td>\n",
              "      <td>totaljobs.com</td>\n",
              "      <td>10.126671</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-534b7a81-18d4-4b50-8e67-01361ebad6b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-534b7a81-18d4-4b50-8e67-01361ebad6b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-534b7a81-18d4-4b50-8e67-01361ebad6b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "TARGET_COLUMN = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhX-C764XzeJ"
      },
      "source": [
        "### Preprocessing text data\n",
        "\n",
        "Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
        "\n",
        "__Your task__ is to lowercase and tokenize all texts under `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for performance reasons.\n",
        "\n",
        "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHjFV2KdXzeK",
        "outputId": "8c8e29cc-cd70-4ec1-b19b-52f70e2e4909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text:\n",
            "2         Mathematical Modeller / Simulation Analyst / O...\n",
            "100002    A successful and high achieving specialist sch...\n",
            "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Raw text:\")\n",
        "print(data[\"FullDescription\"][2::100000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Sc0S0ecIXzeL"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#TODO YOUR CODE HERE\n",
        " \n",
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "data['Title'] = data['Title'].apply(\n",
        "    lambda x: ' '.join(tokenizer.tokenize(str(x).lower())))\n",
        "data['FullDescription'] = data['FullDescription'].apply(\n",
        "    lambda x: ' '.join(tokenizer.tokenize(x.lower()))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eka5pDO2XzeL"
      },
      "source": [
        "Now we can assume that our text is a space-separated list of tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdlGEQ0UXzeM",
        "outputId": "8aa7be2e-b13d-4808-e730-5db623a39fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9npd7T9XzeM"
      },
      "source": [
        "Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
        "\n",
        "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Pb5XezlxXzeN"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "token_counts = Counter()\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "for row in data['FullDescription'].values:\n",
        "    token_counts.update(row.split())\n",
        "\n",
        "for row in data['Title'].values:\n",
        "    token_counts.update(row.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt7fBLX3XzeN",
        "outputId": "82078c17-8a31-43f6-a2c9-c920e521c33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 202704\n",
            "('and', 2657388)\n",
            "('.', 2523216)\n",
            "(',', 2318606)\n",
            "('the', 2080994)\n",
            "('to', 2019884)\n",
            "...\n",
            "('improvemen', 1)\n",
            "('techniciancivil', 1)\n",
            "('mlnlycke', 1)\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "_V9RCQSaXzeO",
        "outputId": "4f35da11-75e6-4c74-a785-8acb497c52c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Let's see how many words are there for each count\n",
        "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
        "plt.xlabel(\"Word counts\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzdpUfZZXzeO"
      },
      "source": [
        "__Task 1.1__ Get a list of all tokens that occur at least 10 times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GSW0QTAIXzeP"
      },
      "outputs": [],
      "source": [
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = sorted(t for t, c in token_counts.items() if c >= min_count)#TODO<YOUR CODE HERE>\n",
        "\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNkAM6lOXzeP",
        "outputId": "b25935cb-b13d-4d98-d36d-2a8629a99fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 34158\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary size:\", len(tokens))\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up2ab5alXzeQ"
      },
      "source": [
        "__Task 1.2__ Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QHS59kNeXzeQ"
      },
      "outputs": [],
      "source": [
        "token_to_id = {}\n",
        "for idx, token in enumerate(tokens):\n",
        "    token_to_id[token] = idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3np4GtZnXzeR",
        "outputId": "5016a907-8235-4f81-d078-59ee08eb09e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwHnlPEmNT3",
        "outputId": "1bc9366e-897a-445e-9798-6970087c1fae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'UNK': 0,\n",
              " 'PAD': 1,\n",
              " '\"': 2,\n",
              " '$': 3,\n",
              " '$****': 4,\n",
              " '$****$****': 5,\n",
              " '$****;': 6,\n",
              " '%': 7,\n",
              " '%)': 8,\n",
              " '%),': 9,\n",
              " '%).': 10,\n",
              " '%****': 11,\n",
              " '%,': 12,\n",
              " '%.': 13,\n",
              " '%/': 14,\n",
              " '%;': 15,\n",
              " '&': 16,\n",
              " '&****': 17,\n",
              " '&/': 18,\n",
              " \"'\": 19,\n",
              " \"'&\": 20,\n",
              " \"''\": 21,\n",
              " \"')\": 22,\n",
              " \"').\": 23,\n",
              " \"'****\": 24,\n",
              " \"'****'\": 25,\n",
              " \"',\": 26,\n",
              " \"'.\": 27,\n",
              " \"';\": 28,\n",
              " \"'>\": 29,\n",
              " \"'>****\": 30,\n",
              " \"'>•\": 31,\n",
              " \"'?\": 32,\n",
              " '(': 33,\n",
              " '($****': 34,\n",
              " '(%': 35,\n",
              " '(&': 36,\n",
              " \"('\": 37,\n",
              " '((': 38,\n",
              " '()': 39,\n",
              " '().': 40,\n",
              " '(****': 41,\n",
              " '(****%)': 42,\n",
              " '(****)': 43,\n",
              " '(****)(': 44,\n",
              " '(****)****': 45,\n",
              " '(****),': 46,\n",
              " '(****).': 47,\n",
              " '(********': 48,\n",
              " '(********)': 49,\n",
              " '(****/': 50,\n",
              " '(****/****': 51,\n",
              " '(****/****)': 52,\n",
              " '(****/****),': 53,\n",
              " '(****/****/****)': 54,\n",
              " '(****:': 55,\n",
              " '(****:****': 56,\n",
              " '(****:****)': 57,\n",
              " '(****:****:****)': 58,\n",
              " '(.': 59,\n",
              " '(>': 60,\n",
              " '(>****': 61,\n",
              " '(?)': 62,\n",
              " '(‘': 63,\n",
              " '(“': 64,\n",
              " ')': 65,\n",
              " ')&': 66,\n",
              " \")'\": 67,\n",
              " ')(': 68,\n",
              " '))': 69,\n",
              " ')).': 70,\n",
              " ')****': 71,\n",
              " '),': 72,\n",
              " ').': 73,\n",
              " ').•': 74,\n",
              " ')/': 75,\n",
              " '):': 76,\n",
              " ');': 77,\n",
              " ')>': 78,\n",
              " ')?': 79,\n",
              " ')–': 80,\n",
              " ')•': 81,\n",
              " '****': 82,\n",
              " '****%': 83,\n",
              " '****%)': 84,\n",
              " '****%,': 85,\n",
              " '****%.': 86,\n",
              " '****&': 87,\n",
              " '****&****': 88,\n",
              " \"****'\": 89,\n",
              " \"****'****\": 90,\n",
              " \"****'********'****\": 91,\n",
              " \"****',\": 92,\n",
              " \"****'>\": 93,\n",
              " '****(': 94,\n",
              " '****(****': 95,\n",
              " '****(****)': 96,\n",
              " '****(****)(': 97,\n",
              " '****(****)****': 98,\n",
              " '****)': 99,\n",
              " '****)****': 100,\n",
              " '****),': 101,\n",
              " '****).': 102,\n",
              " '****):': 103,\n",
              " '*******': 104,\n",
              " '********': 105,\n",
              " '********%': 106,\n",
              " '********)': 107,\n",
              " '************': 108,\n",
              " '********,': 109,\n",
              " '********.': 110,\n",
              " '********/': 111,\n",
              " '********?': 112,\n",
              " '****,': 113,\n",
              " '****.': 114,\n",
              " '****.****': 115,\n",
              " '****/': 116,\n",
              " '****/****': 117,\n",
              " '****/****)': 118,\n",
              " '****/****).': 119,\n",
              " '****/****/': 120,\n",
              " '****/****/****': 121,\n",
              " '****/****/****)': 122,\n",
              " '****/****/****/****': 123,\n",
              " '****/****:': 124,\n",
              " '****/****;': 125,\n",
              " '****:': 126,\n",
              " '****:****': 127,\n",
              " '****:****)': 128,\n",
              " '****:****),': 129,\n",
              " '****:****,': 130,\n",
              " '****:****:': 131,\n",
              " '****:****:****': 132,\n",
              " '****:****:****)': 133,\n",
              " '****:****;': 134,\n",
              " '****;': 135,\n",
              " '****;****': 136,\n",
              " '****?': 137,\n",
              " '****???': 138,\n",
              " '****[': 139,\n",
              " '****]': 140,\n",
              " '****`': 141,\n",
              " '****`****': 142,\n",
              " '****–': 143,\n",
              " '****–****': 144,\n",
              " '****’': 145,\n",
              " '****’****': 146,\n",
              " '****”': 147,\n",
              " '****…': 148,\n",
              " '++': 149,\n",
              " '++)': 150,\n",
              " '++),': 151,\n",
              " '++).': 152,\n",
              " '++,': 153,\n",
              " '++.': 154,\n",
              " '++/': 155,\n",
              " '++;': 156,\n",
              " '++?': 157,\n",
              " ',': 158,\n",
              " ',&': 159,\n",
              " ',(': 160,\n",
              " ',)': 161,\n",
              " ',).': 162,\n",
              " ',****': 163,\n",
              " ',,': 164,\n",
              " ',.': 165,\n",
              " ',/': 166,\n",
              " ',;': 167,\n",
              " ',??': 168,\n",
              " '.': 169,\n",
              " '.&': 170,\n",
              " \".'\": 171,\n",
              " '.(': 172,\n",
              " '.)': 173,\n",
              " '.),': 174,\n",
              " '.).': 175,\n",
              " '.);': 176,\n",
              " '.****': 177,\n",
              " '.****%': 178,\n",
              " '.****)': 179,\n",
              " '.********': 180,\n",
              " '.****/': 181,\n",
              " '.,': 182,\n",
              " './': 183,\n",
              " './/': 184,\n",
              " '.:': 185,\n",
              " '.;': 186,\n",
              " '.>': 187,\n",
              " '.?': 188,\n",
              " '.??': 189,\n",
              " '.]': 190,\n",
              " '.\\u200b': 191,\n",
              " '.’': 192,\n",
              " '.”': 193,\n",
              " '.•': 194,\n",
              " '.\\uf0a7': 195,\n",
              " '.\\uf0b7': 196,\n",
              " '/': 197,\n",
              " '/(': 198,\n",
              " '/)': 199,\n",
              " '/****': 200,\n",
              " '/****)': 201,\n",
              " '/****).': 202,\n",
              " '/********/': 203,\n",
              " '/****/': 204,\n",
              " '/****/****': 205,\n",
              " '/****/****)': 206,\n",
              " '/****/****/': 207,\n",
              " '/****/****/****': 208,\n",
              " '/****:': 209,\n",
              " '/****?': 210,\n",
              " '/.': 211,\n",
              " '//': 212,\n",
              " '///////': 213,\n",
              " '/>': 214,\n",
              " '/?': 215,\n",
              " '0': 216,\n",
              " '00': 217,\n",
              " '000': 218,\n",
              " '00025': 219,\n",
              " '000company': 220,\n",
              " '000market': 221,\n",
              " '000multi': 222,\n",
              " '000my': 223,\n",
              " '000the': 224,\n",
              " '001': 225,\n",
              " '005': 226,\n",
              " '00am': 227,\n",
              " '00am2': 228,\n",
              " '00am3': 229,\n",
              " '00am4': 230,\n",
              " '00am5': 231,\n",
              " '00am6': 232,\n",
              " '00m': 233,\n",
              " '00pm': 234,\n",
              " '00pm9': 235,\n",
              " '01': 236,\n",
              " '010': 237,\n",
              " '011': 238,\n",
              " '011737015': 239,\n",
              " '01189520151': 240,\n",
              " '012': 241,\n",
              " '013': 242,\n",
              " '014': 243,\n",
              " '015': 244,\n",
              " '019': 245,\n",
              " '02': 246,\n",
              " '03': 247,\n",
              " '04': 248,\n",
              " '044': 249,\n",
              " '046': 250,\n",
              " '05': 251,\n",
              " '05years': 252,\n",
              " '06': 253,\n",
              " '07': 254,\n",
              " '07788318687': 255,\n",
              " '08': 256,\n",
              " '0800': 257,\n",
              " '09': 258,\n",
              " '0am': 259,\n",
              " '0bed': 260,\n",
              " '0k': 261,\n",
              " '0m': 262,\n",
              " '0mq': 263,\n",
              " '0pm': 264,\n",
              " '1': 265,\n",
              " '10': 266,\n",
              " '100': 267,\n",
              " '1000': 268,\n",
              " '100k': 269,\n",
              " '100m': 270,\n",
              " '100million': 271,\n",
              " '1012': 272,\n",
              " '1015': 273,\n",
              " '102': 274,\n",
              " '1020': 275,\n",
              " '106': 276,\n",
              " '106pm': 277,\n",
              " '107': 278,\n",
              " '108': 279,\n",
              " '109': 280,\n",
              " '10am': 281,\n",
              " '10am2pm': 282,\n",
              " '10am3pm': 283,\n",
              " '10am4pm': 284,\n",
              " '10am5pm': 285,\n",
              " '10am6': 286,\n",
              " '10am6pm': 287,\n",
              " '10am7pm': 288,\n",
              " '10bn': 289,\n",
              " '10g': 290,\n",
              " '10hrs': 291,\n",
              " '10k': 292,\n",
              " '10m': 293,\n",
              " '10million': 294,\n",
              " '10pm': 295,\n",
              " '10pm6am': 296,\n",
              " '10th': 297,\n",
              " '10years': 298,\n",
              " '11': 299,\n",
              " '110': 300,\n",
              " '1116': 301,\n",
              " '1118': 302,\n",
              " '112': 303,\n",
              " '113': 304,\n",
              " '115': 305,\n",
              " '11am': 306,\n",
              " '11g': 307,\n",
              " '11i': 308,\n",
              " '11pm': 309,\n",
              " '11th': 310,\n",
              " '12': 311,\n",
              " '120': 312,\n",
              " '120m': 313,\n",
              " '1215': 314,\n",
              " '1216': 315,\n",
              " '1218': 316,\n",
              " '1224': 317,\n",
              " '125': 318,\n",
              " '128pm': 319,\n",
              " '12am': 320,\n",
              " '12m': 321,\n",
              " '12month': 322,\n",
              " '12months': 323,\n",
              " '12mths': 324,\n",
              " '12pm': 325,\n",
              " '12pm2pm': 326,\n",
              " '12pm8pm': 327,\n",
              " '12th': 328,\n",
              " '13': 329,\n",
              " '130': 330,\n",
              " '130m': 331,\n",
              " '13485': 332,\n",
              " '135': 333,\n",
              " '136': 334,\n",
              " '13jan13': 335,\n",
              " '13mk': 336,\n",
              " '13th': 337,\n",
              " '14': 338,\n",
              " '140': 339,\n",
              " '14001': 340,\n",
              " '145': 341,\n",
              " '14688': 342,\n",
              " '14689': 343,\n",
              " '147': 344,\n",
              " '149': 345,\n",
              " '14feb13': 346,\n",
              " '14m': 347,\n",
              " '14th': 348,\n",
              " '15': 349,\n",
              " '150': 350,\n",
              " '1500': 351,\n",
              " '15022': 352,\n",
              " '150m': 353,\n",
              " '1520': 354,\n",
              " '154': 355,\n",
              " '156': 356,\n",
              " '15am': 357,\n",
              " '15m': 358,\n",
              " '15million': 359,\n",
              " '15pm': 360,\n",
              " '15th': 361,\n",
              " '16': 362,\n",
              " '160': 363,\n",
              " '1600': 364,\n",
              " '163': 365,\n",
              " '1630': 366,\n",
              " '165million': 367,\n",
              " '16bit': 368,\n",
              " '16m': 369,\n",
              " '16th': 370,\n",
              " '17': 371,\n",
              " '170': 372,\n",
              " '1700': 373,\n",
              " '17025': 374,\n",
              " '1730': 375,\n",
              " '175': 376,\n",
              " '176': 377,\n",
              " '17m': 378,\n",
              " '17pm': 379,\n",
              " '17th': 380,\n",
              " '17week': 381,\n",
              " '18': 382,\n",
              " '180': 383,\n",
              " '1800': 384,\n",
              " '18000': 385,\n",
              " '18001': 386,\n",
              " '1824': 387,\n",
              " '183': 388,\n",
              " '185': 389,\n",
              " '18k': 390,\n",
              " '18m': 391,\n",
              " '18months': 392,\n",
              " '18th': 393,\n",
              " '19': 394,\n",
              " '190': 395,\n",
              " '197': 396,\n",
              " '1973': 397,\n",
              " '1974': 398,\n",
              " '1976': 399,\n",
              " '1978': 400,\n",
              " '1980': 401,\n",
              " '1982': 402,\n",
              " '1983': 403,\n",
              " '1984': 404,\n",
              " '1985': 405,\n",
              " '1986': 406,\n",
              " '1987': 407,\n",
              " '1988': 408,\n",
              " '1989': 409,\n",
              " '199': 410,\n",
              " '1990': 411,\n",
              " '1991': 412,\n",
              " '1992': 413,\n",
              " '1993': 414,\n",
              " '1994': 415,\n",
              " '1995': 416,\n",
              " '1996': 417,\n",
              " '1997': 418,\n",
              " '1998': 419,\n",
              " '1999': 420,\n",
              " '19jan13': 421,\n",
              " '19th': 422,\n",
              " '1a': 423,\n",
              " '1aa': 424,\n",
              " '1am': 425,\n",
              " '1b': 426,\n",
              " '1bn': 427,\n",
              " '1k': 428,\n",
              " '1lp': 429,\n",
              " '1m': 430,\n",
              " '1million': 431,\n",
              " '1nn': 432,\n",
              " '1nx': 433,\n",
              " '1pgrjobs': 434,\n",
              " '1pm': 435,\n",
              " '1pm3': 436,\n",
              " '1st': 437,\n",
              " '1st3rd': 438,\n",
              " '1stassistantmanager_job': 439,\n",
              " '1stplacegraduaterecruitment': 440,\n",
              " '1week': 441,\n",
              " '1years': 442,\n",
              " '2': 443,\n",
              " '20': 444,\n",
              " '200': 445,\n",
              " '2000': 446,\n",
              " '20000': 447,\n",
              " '2001': 448,\n",
              " '2002': 449,\n",
              " '20022': 450,\n",
              " '2003': 451,\n",
              " '2004': 452,\n",
              " '2005': 453,\n",
              " '2006': 454,\n",
              " '2007': 455,\n",
              " '2008': 456,\n",
              " '2008r': 457,\n",
              " '2008r2': 458,\n",
              " '2009': 459,\n",
              " '200m': 460,\n",
              " '200million': 461,\n",
              " '201': 462,\n",
              " '2010': 463,\n",
              " '2011': 464,\n",
              " '2011number': 465,\n",
              " '2012': 466,\n",
              " '2013': 467,\n",
              " '2013interview': 468,\n",
              " '2013the': 469,\n",
              " '2014': 470,\n",
              " '2015': 471,\n",
              " '201513': 472,\n",
              " '2016': 473,\n",
              " '2017': 474,\n",
              " '2018': 475,\n",
              " '2019': 476,\n",
              " '202011': 477,\n",
              " '2025': 478,\n",
              " '2030': 479,\n",
              " '20a': 480,\n",
              " '20annex': 481,\n",
              " '20application': 482,\n",
              " '20convictions': 483,\n",
              " '20days': 484,\n",
              " '20feb': 485,\n",
              " '20form': 486,\n",
              " '20hrs': 487,\n",
              " '20jan13': 488,\n",
              " '20k': 489,\n",
              " '20m': 490,\n",
              " '20million': 491,\n",
              " '20pm': 492,\n",
              " '20th': 493,\n",
              " '21': 494,\n",
              " '210': 495,\n",
              " '21st': 496,\n",
              " '22': 497,\n",
              " '220': 498,\n",
              " '22000': 499,\n",
              " '22k': 500,\n",
              " '22nd': 501,\n",
              " '23': 502,\n",
              " '23000': 503,\n",
              " '230strong': 504,\n",
              " '237': 505,\n",
              " '23feb': 506,\n",
              " '23rd': 507,\n",
              " '24': 508,\n",
              " '240': 509,\n",
              " '24hour': 510,\n",
              " '24th': 511,\n",
              " '25': 512,\n",
              " '250': 513,\n",
              " '250450': 514,\n",
              " '250m': 515,\n",
              " '2530': 516,\n",
              " '25days': 517,\n",
              " '25hrs': 518,\n",
              " '25k': 519,\n",
              " '25m': 520,\n",
              " '25million': 521,\n",
              " '25th': 522,\n",
              " '26': 523,\n",
              " '260': 524,\n",
              " '26262': 525,\n",
              " '2630': 526,\n",
              " '26jan': 527,\n",
              " '26th': 528,\n",
              " '27': 529,\n",
              " '27000': 530,\n",
              " '27001': 531,\n",
              " '275': 532,\n",
              " '279': 533,\n",
              " '27jan': 534,\n",
              " '27k': 535,\n",
              " '27m': 536,\n",
              " '27th': 537,\n",
              " '28': 538,\n",
              " '280': 539,\n",
              " '28k': 540,\n",
              " '28pm': 541,\n",
              " '28th': 542,\n",
              " '29': 543,\n",
              " '29th': 544,\n",
              " '2aa': 545,\n",
              " '2am': 546,\n",
              " '2b': 547,\n",
              " '2bn': 548,\n",
              " '2d': 549,\n",
              " '2form': 550,\n",
              " '2hrs': 551,\n",
              " '2ju': 552,\n",
              " '2k': 553,\n",
              " '2m': 554,\n",
              " '2million': 555,\n",
              " '2months': 556,\n",
              " '2nd': 557,\n",
              " '2ndline': 558,\n",
              " '2pm': 559,\n",
              " '2pm10pm': 560,\n",
              " '2week': 561,\n",
              " '2x': 562,\n",
              " '2years': 563,\n",
              " '2yrs': 564,\n",
              " '3': 565,\n",
              " '30': 566,\n",
              " '300': 567,\n",
              " '300m': 568,\n",
              " '300million': 569,\n",
              " '3035': 570,\n",
              " '3035k': 571,\n",
              " '304': 572,\n",
              " '3040': 573,\n",
              " '305': 574,\n",
              " '3050': 575,\n",
              " '305pm': 576,\n",
              " '306': 577,\n",
              " '306pm': 578,\n",
              " '308': 579,\n",
              " '309pm': 580,\n",
              " '30am': 581,\n",
              " '30am1': 582,\n",
              " '30am12': 583,\n",
              " '30am1pm': 584,\n",
              " '30am3': 585,\n",
              " '30am4': 586,\n",
              " '30am4pm': 587,\n",
              " '30am5': 588,\n",
              " '30am5pm': 589,\n",
              " '30am6': 590,\n",
              " '30am6pm': 591,\n",
              " '30am8': 592,\n",
              " '30children': 593,\n",
              " '30countries': 594,\n",
              " '30hrs': 595,\n",
              " '30k': 596,\n",
              " '30m': 597,\n",
              " '30million': 598,\n",
              " '30pm': 599,\n",
              " '30pm7': 600,\n",
              " '30pm8': 601,\n",
              " '30pm9': 602,\n",
              " '30pm9pm': 603,\n",
              " '30th': 604,\n",
              " '31': 605,\n",
              " '310': 606,\n",
              " '312': 607,\n",
              " '31st': 608,\n",
              " '32': 609,\n",
              " '320': 610,\n",
              " '32bit': 611,\n",
              " '33': 612,\n",
              " '333': 613,\n",
              " '336': 614,\n",
              " '33k': 615,\n",
              " '34': 616,\n",
              " '340': 617,\n",
              " '35': 618,\n",
              " '350': 619,\n",
              " '35000': 620,\n",
              " '350m': 621,\n",
              " '35635': 622,\n",
              " '35k': 623,\n",
              " '35m': 624,\n",
              " '36': 625,\n",
              " '360': 626,\n",
              " '365': 627,\n",
              " '36months': 628,\n",
              " '37': 629,\n",
              " '371': 630,\n",
              " '37hour': 631,\n",
              " '37hrs': 632,\n",
              " '38': 633,\n",
              " '39': 634,\n",
              " '39hrs': 635,\n",
              " '3aa': 636,\n",
              " '3am': 637,\n",
              " '3bn': 638,\n",
              " '3d': 639,\n",
              " '3days': 640,\n",
              " '3e': 641,\n",
              " '3g': 642,\n",
              " '3gpp': 643,\n",
              " '3k': 644,\n",
              " '3m': 645,\n",
              " '3million': 646,\n",
              " '3month': 647,\n",
              " '3months': 648,\n",
              " '3par': 649,\n",
              " '3pl': 650,\n",
              " '3pm': 651,\n",
              " '3pm11pm': 652,\n",
              " '3rd': 653,\n",
              " '3rdparty': 654,\n",
              " '3x': 655,\n",
              " '3years': 656,\n",
              " '3yrs': 657,\n",
              " '4': 658,\n",
              " '40': 659,\n",
              " '400': 660,\n",
              " '4000': 661,\n",
              " '40000': 662,\n",
              " '400m': 663,\n",
              " '4045': 664,\n",
              " '40hrs': 665,\n",
              " '40k': 666,\n",
              " '40m': 667,\n",
              " '40million': 668,\n",
              " '41': 669,\n",
              " '410': 670,\n",
              " '415': 671,\n",
              " '42': 672,\n",
              " '43': 673,\n",
              " '44': 674,\n",
              " '45': 675,\n",
              " '450': 676,\n",
              " '4550': 677,\n",
              " '45am': 678,\n",
              " '45am6pm': 679,\n",
              " '45k': 680,\n",
              " '45m': 681,\n",
              " '45pm': 682,\n",
              " '46': 683,\n",
              " '47': 684,\n",
              " '48': 685,\n",
              " '48pm': 686,\n",
              " '49': 687,\n",
              " '4am': 688,\n",
              " '4children': 689,\n",
              " '4d': 690,\n",
              " '4days': 691,\n",
              " '4hrs': 692,\n",
              " '4k': 693,\n",
              " '4m': 694,\n",
              " '4million': 695,\n",
              " '4off': 696,\n",
              " '4on': 697,\n",
              " '4pm': 698,\n",
              " '4pm8pm': 699,\n",
              " '4social': 700,\n",
              " '4star': 701,\n",
              " '4th': 702,\n",
              " '4week': 703,\n",
              " '5': 704,\n",
              " '50': 705,\n",
              " '500': 706,\n",
              " '500m': 707,\n",
              " '5060': 708,\n",
              " '50am': 709,\n",
              " '50k': 710,\n",
              " '50m': 711,\n",
              " '50million': 712,\n",
              " '50pm': 713,\n",
              " '51': 714,\n",
              " '510': 715,\n",
              " '515': 716,\n",
              " '52': 717,\n",
              " '53': 718,\n",
              " '530pm': 719,\n",
              " '54': 720,\n",
              " '55': 721,\n",
              " '550m': 722,\n",
              " '551': 723,\n",
              " '55th': 724,\n",
              " '56': 725,\n",
              " '57': 726,\n",
              " '58': 727,\n",
              " '59': 728,\n",
              " '59pm': 729,\n",
              " '5am': 730,\n",
              " '5billion': 731,\n",
              " '5days': 732,\n",
              " '5hours': 733,\n",
              " '5hrs': 734,\n",
              " '5k': 735,\n",
              " '5m': 736,\n",
              " '5mb': 737,\n",
              " '5million': 738,\n",
              " '5pm': 739,\n",
              " '5pm9pm': 740,\n",
              " '5q': 741,\n",
              " '5s': 742,\n",
              " '5star': 743,\n",
              " '5th': 744,\n",
              " '5why': 745,\n",
              " '5x': 746,\n",
              " '5y': 747,\n",
              " '5years': 748,\n",
              " '5yrs': 749,\n",
              " '6': 750,\n",
              " '60': 751,\n",
              " '600': 752,\n",
              " '600m': 753,\n",
              " '60k': 754,\n",
              " '60m': 755,\n",
              " '61': 756,\n",
              " '610': 757,\n",
              " '610am': 758,\n",
              " '612': 759,\n",
              " '61656': 760,\n",
              " '62': 761,\n",
              " '63': 762,\n",
              " '64': 763,\n",
              " '64bit': 764,\n",
              " '65': 765,\n",
              " '65365': 766,\n",
              " '65822': 767,\n",
              " '65m': 768,\n",
              " '66': 769,\n",
              " '67': 770,\n",
              " '670': 771,\n",
              " '68': 772,\n",
              " '68am': 773,\n",
              " '69': 774,\n",
              " '69am': 775,\n",
              " '6am': 776,\n",
              " '6am2pm': 777,\n",
              " '6am6pm': 778,\n",
              " '6jb': 779,\n",
              " '6k': 780,\n",
              " '6m': 781,\n",
              " '6million': 782,\n",
              " '6month': 783,\n",
              " '6months': 784,\n",
              " '6pm': 785,\n",
              " '6pm6am': 786,\n",
              " '6th': 787,\n",
              " '6weeks': 788,\n",
              " '7': 789,\n",
              " '70': 790,\n",
              " '700': 791,\n",
              " '7000': 792,\n",
              " '70m': 793,\n",
              " '71': 794,\n",
              " '710': 795,\n",
              " '712': 796,\n",
              " '72': 797,\n",
              " '73': 798,\n",
              " '74': 799,\n",
              " '75': 800,\n",
              " '750': 801,\n",
              " '750m': 802,\n",
              " '75m': 803,\n",
              " '76': 804,\n",
              " '77': 805,\n",
              " '78': 806,\n",
              " '79': 807,\n",
              " '7am': 808,\n",
              " '7am10am': 809,\n",
              " '7am11am': 810,\n",
              " '7am11pm': 811,\n",
              " '7am2pm': 812,\n",
              " '7am3': 813,\n",
              " '7am3pm': 814,\n",
              " '7am4pm': 815,\n",
              " '7am5pm': 816,\n",
              " '7am7pm': 817,\n",
              " '7days': 818,\n",
              " '7k': 819,\n",
              " '7m': 820,\n",
              " '7million': 821,\n",
              " '7pm': 822,\n",
              " '7pm7am': 823,\n",
              " '7th': 824,\n",
              " '8': 825,\n",
              " '80': 826,\n",
              " '800': 827,\n",
              " '80800': 828,\n",
              " '8090': 829,\n",
              " '80m': 830,\n",
              " '81': 831,\n",
              " '810': 832,\n",
              " '812': 833,\n",
              " '82': 834,\n",
              " '8226': 835,\n",
              " '8232': 836,\n",
              " '83': 837,\n",
              " '84': 838,\n",
              " '85': 839,\n",
              " '850m': 840,\n",
              " '85pm': 841,\n",
              " '86': 842,\n",
              " '87': 843,\n",
              " '88': 844,\n",
              " '88pm': 845,\n",
              " '89': 846,\n",
              " '896': 847,\n",
              " '8a': 848,\n",
              " '8am': 849,\n",
              " '8am12pm': 850,\n",
              " '8am1pm': 851,\n",
              " '8am2pm': 852,\n",
              " '8am4': 853,\n",
              " '8am4pm': 854,\n",
              " '8am5': 855,\n",
              " '8am5pm': 856,\n",
              " '8am6pm': 857,\n",
              " '8am7pm': 858,\n",
              " '8am8pm': 859,\n",
              " '8am9pm': 860,\n",
              " '8c': 861,\n",
              " '8d': 862,\n",
              " '8m': 863,\n",
              " '8pm': 864,\n",
              " '8pm8am': 865,\n",
              " '8sb': 866,\n",
              " '8th': 867,\n",
              " '9': 868,\n",
              " '90': 869,\n",
              " '900': 870,\n",
              " '9000': 871,\n",
              " '9001': 872,\n",
              " '9001en': 873,\n",
              " '9002': 874,\n",
              " '90day': 875,\n",
              " '90m': 876,\n",
              " '91': 877,\n",
              " '912': 878,\n",
              " '92': 879,\n",
              " '93': 880,\n",
              " '9320100': 881,\n",
              " '94': 882,\n",
              " '95': 883,\n",
              " '95pm': 884,\n",
              " '96': 885,\n",
              " '9632': 886,\n",
              " '96pm': 887,\n",
              " '97': 888,\n",
              " '98': 889,\n",
              " '99': 890,\n",
              " '997': 891,\n",
              " '998': 892,\n",
              " '9am': 893,\n",
              " '9am12pm': 894,\n",
              " '9am1pm': 895,\n",
              " '9am2pm': 896,\n",
              " '9am3pm': 897,\n",
              " '9am4pm': 898,\n",
              " '9am5': 899,\n",
              " '9am5pm': 900,\n",
              " '9am6pm': 901,\n",
              " '9am9pm': 902,\n",
              " '9months': 903,\n",
              " '9ph': 904,\n",
              " '9pm': 905,\n",
              " '9th': 906,\n",
              " ':': 907,\n",
              " ':&': 908,\n",
              " \":'\": 909,\n",
              " ':(': 910,\n",
              " ':)': 911,\n",
              " ':****': 912,\n",
              " ':****)': 913,\n",
              " ':********': 914,\n",
              " ':****/': 915,\n",
              " ':****/****': 916,\n",
              " ':****/****/': 917,\n",
              " ':****:': 918,\n",
              " ':****:****': 919,\n",
              " ':,': 920,\n",
              " ':.': 921,\n",
              " ':/': 922,\n",
              " '://': 923,\n",
              " '::': 924,\n",
              " ':>': 925,\n",
              " ':?': 926,\n",
              " ':•': 927,\n",
              " ';': 928,\n",
              " ';)': 929,\n",
              " ';****': 930,\n",
              " ';****/': 931,\n",
              " ';****;****;': 932,\n",
              " ';,': 933,\n",
              " ';.': 934,\n",
              " ';;': 935,\n",
              " ';•': 936,\n",
              " '<': 937,\n",
              " '>': 938,\n",
              " '>****': 939,\n",
              " '>>': 940,\n",
              " '>>>': 941,\n",
              " '>??': 942,\n",
              " '?': 943,\n",
              " \"?'\": 944,\n",
              " '?)': 945,\n",
              " '?).': 946,\n",
              " '?****': 947,\n",
              " '?,': 948,\n",
              " '?.': 949,\n",
              " '?:': 950,\n",
              " '??': 951,\n",
              " '??,': 952,\n",
              " '??.': 953,\n",
              " '???': 954,\n",
              " '????': 955,\n",
              " '??????': 956,\n",
              " '??????????': 957,\n",
              " '????????????': 958,\n",
              " '??????????????': 959,\n",
              " '?”': 960,\n",
              " '[': 961,\n",
              " ']': 962,\n",
              " '],': 963,\n",
              " '],****': 964,\n",
              " '].': 965,\n",
              " ']/': 966,\n",
              " ']:': 967,\n",
              " '^': 968,\n",
              " '_': 969,\n",
              " '__': 970,\n",
              " '_____________________': 971,\n",
              " '___________________________': 972,\n",
              " '________________________________________': 973,\n",
              " '______________________________________________________________________________': 974,\n",
              " '_a': 975,\n",
              " '_experience': 976,\n",
              " '_job': 977,\n",
              " '`': 978,\n",
              " '`,': 979,\n",
              " '`.': 980,\n",
              " '``': 981,\n",
              " 'a': 982,\n",
              " 'a1': 983,\n",
              " 'a1cae': 984,\n",
              " 'a2': 985,\n",
              " 'a24': 986,\n",
              " 'a24connect': 987,\n",
              " 'a3': 988,\n",
              " 'a4': 989,\n",
              " 'a400m': 990,\n",
              " 'a4e': 991,\n",
              " 'a4lfw4l': 992,\n",
              " 'a4lg': 993,\n",
              " 'aa': 994,\n",
              " 'aaa': 995,\n",
              " 'aaad': 996,\n",
              " 'aaappointments': 997,\n",
              " 'aab': 998,\n",
              " 'aac': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "вывод - плохая токенезация"
      ],
      "metadata": {
        "id": "16glx3ZVmW7S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV1F0MGjXzeR"
      },
      "source": [
        "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Nv9hF63_XzeR"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = max_len\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiYFIOhrXzeS"
      },
      "source": [
        "Now let's  encode the categirical data we have.\n",
        "\n",
        "As usual, we shall use one-hot encoding for simplicity. Kudos if you implement more advanced encodings: tf-idf, pseudo-time-series, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFg-o9u8XzeT",
        "outputId": "666657bc-97b3-4cce-b472-3d5a1e94567a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEZ_IkP_XzeX"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I-UG5pjXzeY",
        "outputId": "788b970f-802d-4135-d26a-310c1d49f245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  195814\n",
            "Validation size =  48954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "b7qzGpFqXzeY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "def to_tensors(batch, device):\n",
        "    batch_tensors = dict()\n",
        "    for key, arr in batch.items():\n",
        "        if key in [\"FullDescription\", \"Title\"]:\n",
        "            batch_tensors[key] = torch.tensor(arr, device=device, dtype=torch.int64)\n",
        "        else:\n",
        "            batch_tensors[key] = torch.tensor(arr, device=device)\n",
        "    return batch_tensors\n",
        "\n",
        "\n",
        "def make_batch(data, max_len=None, word_dropout=0, device=device):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if TARGET_COLUMN in data.columns:\n",
        "        batch[TARGET_COLUMN] = data[TARGET_COLUMN].values\n",
        "    \n",
        "    return to_tensors(batch, device)\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJjTerlZXzeZ"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our basic model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "![scheme](https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRs3vLXzea"
      },
      "source": [
        "This clearly doesn't fit into keras' __Sequential__ interface. To build such a network, one will have to use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Jdl59oIoXzea"
      },
      "outputs": [],
      "source": [
        "class SalaryPredictor(nn.Module):\n",
        "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=32):\n",
        "        super().__init__()\n",
        "        self.embed_size = 32\n",
        "        #title emb / desc\n",
        "        self.embedding = nn.Embedding(n_tokens, self.embed_size)\n",
        "        self.conv1 = nn.Conv1d(in_channels=10,\n",
        "                               out_channels=1,\n",
        "                               kernel_size=10)\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=1, stride=5)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(in_channels=10, \n",
        "                               out_channels=1, \n",
        "                               kernel_size=10)\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=1, stride=5)\n",
        "\n",
        "        self.fc1 = nn.Linear(n_cat_features, \n",
        "                             hid_size)\n",
        "        self.fc2 = nn.Linear(42, 1)\n",
        "        \n",
        "    def forward(self, batch):\n",
        "\n",
        "        # Title features\n",
        "        embeded = self.embedding(batch['Title'])\n",
        "        title_out = self.pool1(self.conv1(embeded))\n",
        "\n",
        "        # FullDescription features использую тот же embed\n",
        "        embeded = self.embedding(batch['FullDescription'])\n",
        "        desc_out = self.pool2(self.conv1(embeded))\n",
        "\n",
        "        # cat features\n",
        "        cat_out = self.fc1(batch['Categorical'])\n",
        "        \n",
        "        out = self.fc2(torch.cat((title_out.view(50, -1), desc_out.view(50, -1), cat_out), axis=1))\n",
        "\n",
        "        return out.view(50)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SFP_ru4aXzeb"
      },
      "outputs": [],
      "source": [
        "model = SalaryPredictor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2kgArFpXzec"
      },
      "source": [
        "#### Training and evaluation\n",
        "\n",
        "As usual, we gonna feed our monster with random minibatches of data. \n",
        "\n",
        "As we train, we want to monitor not only loss function, which is computed in log-space, but also the actual error measured in dollars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zi26NeJ-Xzec"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, device=device, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], device=device, **kwargs)\n",
        "            yield batch\n",
        "        \n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAd_UDtQXzed"
      },
      "source": [
        "### Model training\n",
        "\n",
        "We can now fit our model the usual minibatch way. The interesting part is that we train on an infinite stream of minibatches, produced by `iterate_minibatches` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IcxbdzzkXzee"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "BATCH_SIZE = 50\n",
        "EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A5jHsXoOXzef"
      },
      "outputs": [],
      "source": [
        "def print_metrics(model, data, batch_size=BATCH_SIZE, name=\"\", **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # for batch in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
        "        for i in range(len(data) - 50):\n",
        "            batch = make_batch(data[i:i+50], max_len=10)\n",
        "            batch_pred = model(batch)\n",
        "            squared_error += torch.sum(torch.square(batch_pred - batch[TARGET_COLUMN]))\n",
        "            abs_error += torch.sum(torch.abs(batch_pred - batch[TARGET_COLUMN]))\n",
        "            num_samples += len(batch_pred)\n",
        "    mse = squared_error.detach().cpu().numpy() / num_samples\n",
        "    mae = abs_error.detach().cpu().numpy() / num_samples\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % mse)\n",
        "    print(\"Mean absolute error: %.5f\" % mae)\n",
        "    return mse, mae\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "FVZNf32_Xzeg",
        "outputId": "78b68ceb-5f9a-4922-98a6-94ccc4cf5d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n",
            "160000\n",
            "170000\n",
            "180000\n",
            "190000\n",
            " results:\n",
            "Mean square error: 0.10420\n",
            "Mean absolute error: 0.24739\n",
            "epoch: 1\n",
            "0\n",
            "10000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-173d85a8b7ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTARGET_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = SalaryPredictor().to(device)\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    model.train()\n",
        "    for i in range(len(data_train) - 50):\n",
        "        batch = make_batch(data_train[i:i+50], max_len=10)\n",
        "        pred = model(batch)\n",
        "        loss = criterion(pred, batch[TARGET_COLUMN])\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (i + 1 % 10000) == 0:\n",
        "            print(i)\n",
        "            print(loss)\n",
        "    print_metrics(model, data_val, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW0e8Y2XXzeh"
      },
      "source": [
        "### Bonus part: explaining model predictions\n",
        "\n",
        "It's usually a good idea to understand how your model works before you let it make actual decisions. It's simple for linear models: just see which words learned positive or negative weights. However, its much harder for neural networks that learn complex nonlinear dependencies.\n",
        "\n",
        "There are, however, some ways to look inside the black box:\n",
        "* Seeing how model responds to input perturbations\n",
        "* Finding inputs that maximize/minimize activation of some chosen neurons (_read more [on distill.pub](https://distill.pub/2018/building-blocks/)_)\n",
        "* Building local linear approximations to your neural network: [article](https://arxiv.org/abs/1602.04938), [eli5 library](https://github.com/TeamHG-Memex/eli5/tree/master/eli5/formatters)\n",
        "\n",
        "Today we gonna try the first method just because it's the simplest one."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXAtkeb6YEeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WJhA7YiyXzeh"
      },
      "outputs": [],
      "source": [
        "def explain(model, sample, col_name='Title'):\n",
        "    \"\"\" Computes the effect each word had on model predictions \"\"\"\n",
        "    sample = dict(sample)\n",
        "    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n",
        "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n",
        "\n",
        "    for drop_i in range(len(sample_col_tokens)):\n",
        "        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n",
        "                                                   for i, tok in enumerate(sample_col_tokens)) \n",
        "\n",
        "    *predictions_drop_one_token, baseline_pred = model.forward(make_batch(data_drop_one_token, device=device)).detach().cpu()\n",
        "    diffs = baseline_pred - torch.Tensor(predictions_drop_one_token)\n",
        "    return list(zip(sample_col_tokens, diffs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "p1Eb48S-Xzei"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display_html\n",
        "\n",
        "\n",
        "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
        "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
        "              font_style=\"font-size:14px;\"\n",
        "             ):\n",
        "    \n",
        "    def get_color_hex(weight):\n",
        "        rgba = cmap(1. / (1 + np.exp(float(weight))), bytes=True)\n",
        "        return '#%02X%02X%02X' % rgba[:3]\n",
        "    \n",
        "    tokens_html = [\n",
        "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
        "        for token, weight in tokens_and_weights\n",
        "    ]\n",
        "    \n",
        "    \n",
        "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
        "    if display:\n",
        "        display_html(HTML(raw_html))\n",
        "        \n",
        "    return raw_html\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_batch(data[0:2], device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "YJa25osqYa60",
        "outputId": "9f1f8135-5b78-4982-fd9c-cb036be5646f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6a4721873694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-e7e277ba96e8>\u001b[0m in \u001b[0;36mmake_batch\u001b[0;34m(data, max_len, word_dropout, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[1;32m     25\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullDescription\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullDescription\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Categorical'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4c09d739ae9a>\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(sequences, max_len)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPAD_IX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrow_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNK_IX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward(make_batch(data[0:2], device=device)).detach().cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "2k3wDUbRYFp1",
        "outputId": "e2f5495b-7dd7-4ae3-a6e9-fe0a76e2f5e9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-31676cf1f05a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-e7e277ba96e8>\u001b[0m in \u001b[0;36mmake_batch\u001b[0;34m(data, max_len, word_dropout, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[1;32m     25\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullDescription\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullDescription\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Categorical'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4c09d739ae9a>\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(sequences, max_len)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPAD_IX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrow_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNK_IX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "AplOyHQjXzej",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "outputId": "e6b0d02f-15fd-4841-b72c-082f69ede4be"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-328fedfdee34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m36605\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens_and_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdraw_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'font-size:20px;'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokens_and_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FullDescription\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-af5c34d76d65>\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(model, sample, col_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                    for i, tok in enumerate(sample_col_tokens)) \n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;34m*\u001b[0m\u001b[0mpredictions_drop_one_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_drop_one_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdiffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_drop_one_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_col_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-e7e277ba96e8>\u001b[0m in \u001b[0;36mmake_batch\u001b[0;34m(data, max_len, word_dropout, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[1;32m     25\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullDescription\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FullDescription\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Categorical'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4c09d739ae9a>\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(sequences, max_len)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPAD_IX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrow_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNK_IX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
          ]
        }
      ],
      "source": [
        "i = 36605\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqfNokj1Xzek"
      },
      "outputs": [],
      "source": [
        "i = 12077\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Qh2qpiw3Xzek",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "6432471e-6bd5-4f81-ad10-d4f60790864e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 136968\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-ae83e986d2fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Salary (gbp):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokens_and_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1270\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SalaryPredictor' object has no attribute 'predict'"
          ]
        }
      ],
      "source": [
        "i = np.random.randint(len(data))\n",
        "print(\"Index:\", i)\n",
        "print(\"Salary (gbp):\", np.expm1(model.predict(make_batch(data.iloc[i: i+1], device=device)).detach().cpu()))\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyIFWfbJXzek"
      },
      "source": [
        "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}