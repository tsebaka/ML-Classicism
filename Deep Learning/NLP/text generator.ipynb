{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "y27PDJOZB4aS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import bs4 as bs\n",
        "import re\n",
        "import urllib.request\n",
        "import warnings\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "class parse_and_prepare():\n",
        "    def __init__(self, EOS=False):\n",
        "        self.EOS = EOS\n",
        "\n",
        "    def parse(self, sites):\n",
        "        text = []\n",
        "        for site in sites:\n",
        "            scrapped_data = urllib.request.urlopen(site)\n",
        "            article = scrapped_data.read()\n",
        "\n",
        "            parsed_article = bs.BeautifulSoup(article, 'lxml')\n",
        "            paragraphs = parsed_article.find_all('p')\n",
        "            article_text = \"\"\n",
        "            for p in paragraphs:\n",
        "                article_text += p.text\n",
        "\n",
        "            processed_article = article_text.lower()\n",
        "            if self.EOS:\n",
        "                processed_article = re.sub('[^a-zA-Z.]', ' ', processed_article)\n",
        "            else:\n",
        "                processed_article = re.sub('[^a-zA-Z]', ' ', processed_article)\n",
        "\n",
        "            processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
        "            all_sentences = nltk.sent_tokenize(processed_article)\n",
        "\n",
        "            new_text = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
        "\n",
        "            for sentence in new_text:\n",
        "                text.append(' '.join(sentence[:-1]))\n",
        "\n",
        "        return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6-W4bYE5DvS",
        "outputId": "39d0f7a4-899b-46cc-d197-fd8d8cf11901"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sites =['https://breakingbad.fandom.com/wiki/Walter_White',\n",
        "         'https://en.wikipedia.org/wiki/Breaking_Bad',\n",
        "         'https://breakingbad.fandom.com/wiki/Jesse_Pinkman',\n",
        "         'https://breakingbad.fandom.com/wiki/Gustavo_Fring', \n",
        "        'https://breakingbad.fandom.com/wiki/Jimmy_McGill',\n",
        "        'https://breakingbad.fandom.com/wiki/Mike_Ehrmantraut',\n",
        "        'https://breakingbad.fandom.com/wiki/Skyler_White',\n",
        "        'https://breakingbad.fandom.com/wiki/Hank_Schrader',\n",
        "        'https://en.wikiquote.org/wiki/Breaking_Bad',\n",
        "        'https://en.wikipedia.beta.wmflabs.org/wiki/Breaking_Bad',\n",
        "        'https://www.wikidata.org/wiki/Q1079',\n",
        "        'https://marcelsadusbreakingbadwiki.wordpress.com/',\n",
        "        'https://de.zxc.wiki/wiki/Breaking_Bad',\n",
        "        'https://breakingbad.fandom.com/wiki/Lalo_Salamanca',\n",
        "        'https://breakingbad.fandom.com/wiki/Lydia_Rodarte-Quayle',\n",
        "        'https://breakingbad.fandom.com/wiki/Todd_Alquist',\n",
        "        'https://breakingbad.fandom.com/wiki/Marie_Schrader',\n",
        "        'https://breakingbad.fandom.com/wiki/Walter_White_Jr.',\n",
        "        'https://breakingbad.fandom.com/wiki/Kim_Wexler',\n",
        "        'https://breakingbad.fandom.com/wiki/Walter_White_Jr.',\n",
        "        'https://breakingbad.fandom.com/wiki/Chuck_McGill',\n",
        "        'https://breakingbad.fandom.com/wiki/Nacho_Varga',\n",
        "        'https://breakingbad.fandom.com/wiki/Season_1_(Better_Call_Saul)'\n",
        "         ]\n",
        "\n",
        "parser = parse_and_prepare(EOS=True)\n",
        "text = parser.parse(sites)"
      ],
      "metadata": {
        "id": "f87LX6Ej6P4E"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text:\n",
        "    print(sentence)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4bx_yZf5dV8",
        "outputId": "591a4a8e-c549-4f0b-8707-cc841abd8d5b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main walter white portrayed by bryan cranston character information full name walter hartwell white sr. aliases waltheisenbergmr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkW84LWzDqG6",
        "outputId": "16eec8ca-9532-4114-d192-dc973cfeb2eb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8081"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dictionary():\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if not word in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            self.idx += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.idx\n",
        "\n",
        "class Corpus():\n",
        "    def __init__(self):\n",
        "        self.dictionary = Dictionary()\n",
        "    \n",
        "    def get_data(self, text, batch_size):\n",
        "        tokens_size = 0\n",
        "\n",
        "        for sentence in text:\n",
        "            words = sentence.split() + ['<EOS>']\n",
        "            tokens_size += len(words)\n",
        "            for word in words:\n",
        "                self.dictionary.add_word(word)\n",
        "\n",
        "        ids = torch.LongTensor(tokens_size)\n",
        "        size = 0\n",
        "        for sentence in text:\n",
        "            words = sentence.split() + ['<EOS>']\n",
        "            for word in words:\n",
        "                ids[size] = self.dictionary.word2idx[word]\n",
        "                size += 1\n",
        "    \n",
        "        num_batches = size // batch_size\n",
        "        ids = ids[:num_batches*batch_size]\n",
        "\n",
        "        return ids.view(batch_size, -1)"
      ],
      "metadata": {
        "id": "HUjneJ1wlUGx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 1\n",
        "max_epochs = 5\n",
        "batch_size = 20\n",
        "seq_length = 20\n",
        "lr = 0.002\n",
        "\n",
        "corpus = Corpus()\n",
        "ids = corpus.get_data(text, batch_size)\n",
        "vocab_size = corpus.dictionary.idx\n",
        "num_batches = ids.size(1) // seq_length"
      ],
      "metadata": {
        "id": "r04qZZBcsFSX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, \n",
        "                 hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, \n",
        "                                      embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size, \n",
        "                            hidden_size,\n",
        "                            num_layers,\n",
        "                            # bid\n",
        "                            batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size,\n",
        "                             vocab_size)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        out, (h, c) = self.lstm(x, h)\n",
        "\n",
        "        out = out.reshape(out.size(0)*out.size(1), out.size(2))\n",
        "\n",
        "        out = self.fc1(out)\n",
        "\n",
        "        return out, (h, c)\n",
        "\n",
        "model = LSTM(vocab_size,\n",
        "             embedding_size,\n",
        "             hidden_size,\n",
        "             num_layers).to(device)"
      ],
      "metadata": {
        "id": "Gp6bh87ZucpY"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "j_BbHOUqx1mM"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detach(states):\n",
        "    return [state.detach() for state in states] "
      ],
      "metadata": {
        "id": "-yKX5t3OyAiF"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(max_epochs):\n",
        "    states = (torch.randn(num_layers, batch_size, hidden_size).to(device),\n",
        "              torch.randn(num_layers, batch_size, hidden_size).to(device))\n",
        "    \n",
        "    for pos in range(0, ids.size(1) - seq_length, seq_length):\n",
        "        seq = ids[:, pos:pos+seq_length].to(device)\n",
        "        target = ids[:, (pos+1):(pos+1)+seq_length].to(device)\n",
        "\n",
        "        states = detach(states)\n",
        "        outputs, states = model.forward(seq, states)\n",
        "\n",
        "        loss = criterion(outputs, target.reshape(-1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "\n",
        "        step = (pos+1) // seq_length\n",
        "        if step % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step[{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
        "                   .format(epoch+1, max_epochs, step,\n",
        "                           num_batches, loss.item(),\n",
        "                           np.exp(loss.item())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZyUJAjeyHsj",
        "outputId": "9ddeb097-5167-4968-b20d-f5695cfde221"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step[0/505], Loss: 9.3116, Perplexity: 11065.33\n",
            "Epoch [1/5], Step[100/505], Loss: 6.1063, Perplexity: 448.69\n",
            "Epoch [1/5], Step[200/505], Loss: 5.4447, Perplexity: 231.52\n",
            "Epoch [1/5], Step[300/505], Loss: 5.7483, Perplexity: 313.65\n",
            "Epoch [1/5], Step[400/505], Loss: 5.0267, Perplexity: 152.43\n",
            "Epoch [1/5], Step[500/505], Loss: 5.3698, Perplexity: 214.81\n",
            "Epoch [2/5], Step[0/505], Loss: 5.0580, Perplexity: 157.28\n",
            "Epoch [2/5], Step[100/505], Loss: 4.6263, Perplexity: 102.13\n",
            "Epoch [2/5], Step[200/505], Loss: 3.8878, Perplexity: 48.80\n",
            "Epoch [2/5], Step[300/505], Loss: 4.0105, Perplexity: 55.18\n",
            "Epoch [2/5], Step[400/505], Loss: 3.7000, Perplexity: 40.45\n",
            "Epoch [2/5], Step[500/505], Loss: 3.9862, Perplexity: 53.85\n",
            "Epoch [3/5], Step[0/505], Loss: 4.1631, Perplexity: 64.27\n",
            "Epoch [3/5], Step[100/505], Loss: 3.2952, Perplexity: 26.98\n",
            "Epoch [3/5], Step[200/505], Loss: 2.8212, Perplexity: 16.80\n",
            "Epoch [3/5], Step[300/505], Loss: 2.7664, Perplexity: 15.90\n",
            "Epoch [3/5], Step[400/505], Loss: 2.5901, Perplexity: 13.33\n",
            "Epoch [3/5], Step[500/505], Loss: 2.6770, Perplexity: 14.54\n",
            "Epoch [4/5], Step[0/505], Loss: 3.1484, Perplexity: 23.30\n",
            "Epoch [4/5], Step[100/505], Loss: 2.2771, Perplexity:  9.75\n",
            "Epoch [4/5], Step[200/505], Loss: 1.9456, Perplexity:  7.00\n",
            "Epoch [4/5], Step[300/505], Loss: 1.9077, Perplexity:  6.74\n",
            "Epoch [4/5], Step[400/505], Loss: 1.9443, Perplexity:  6.99\n",
            "Epoch [4/5], Step[500/505], Loss: 1.7321, Perplexity:  5.65\n",
            "Epoch [5/5], Step[0/505], Loss: 2.3958, Perplexity: 10.98\n",
            "Epoch [5/5], Step[100/505], Loss: 1.5273, Perplexity:  4.61\n",
            "Epoch [5/5], Step[200/505], Loss: 1.3699, Perplexity:  3.93\n",
            "Epoch [5/5], Step[300/505], Loss: 1.3382, Perplexity:  3.81\n",
            "Epoch [5/5], Step[400/505], Loss: 1.3292, Perplexity:  3.78\n",
            "Epoch [5/5], Step[500/505], Loss: 1.1387, Perplexity:  3.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 200\n",
        "\n",
        "with torch.no_grad():\n",
        "    with open('sample.txt', 'w') as f:\n",
        "\n",
        "        state = (torch.zeros(num_layers, 1, hidden_size).to(device),\n",
        "                 torch.zeros(num_layers, 1, hidden_size).to(device))\n",
        "\n",
        "        prob = torch.ones(vocab_size)\n",
        "        input = torch.multinomial(prob, num_samples=1).unsqueeze(1).to(device)\n",
        "\n",
        "        for i in range(num_samples):\n",
        "            output, state = model(input, state)\n",
        "\n",
        "            prob = output.exp()\n",
        "            word_id = torch.multinomial(prob, num_samples=1).item()\n",
        "\n",
        "            input.fill_(word_id)\n",
        "\n",
        "            word = corpus.dictionary.idx2word[word_id]\n",
        "            word = '\\n' if word == '<eos>' else word + ' '\n",
        "            print(word, end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBUf2nIW4dg6",
        "outputId": "f080236c-51b1-42c3-8397-86588e87f950"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pinning  that  the  trailer  <EOS>  gus  offers  t  trust  hector  s  deal  and  walt  made  increasingly  rodarte  for  eleven  class  late  <EOS>  his  face  remains  in  mexico  gus  death.the  dea  trackers  about  the  max  s  efforts  to  become  less  and  less  reluctant  to  resort  to  which  jesse  now  that  their  right  is  the  website  of  all  their  cases  tuco  <EOS>  walt  contained  and  jesse  in  the  position  that  walt  is  retired  in  town  <EOS>  knowing  that  walt  no  longer  calling  jesse  s  drug  money  and  needs  if  he  poisoned  them  to  his  dad  a  car  can  call  hank  schrader  <EOS>  a  waitress  later  gomez  and  walt  go  into  one  of  the  time  walter  white  and  jesse  pinkman  entered  the  drug  business  while  hank  and  walt  made  a  mistake  found  the  leader  of  a  year  old  boy  he  d  known  since  the  boy  was  so  anyway  could  receive  help  from  some  police  officers  stand  and  as  a  well  trained  warehouse  the  guy  for  his  gain  confessing  in  and  <EOS>  walter  offers  walter  jr.  for  his  first  life  during  his  childhood  which  was  the  most  critically  acclaimed  of  albuquerque  new  mexico  and  the  other  other  partners  <EOS>  despite  his  desire  to  walter  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BX69_HRxFMQc"
      },
      "execution_count": 65,
      "outputs": []
    }
  ]
}
